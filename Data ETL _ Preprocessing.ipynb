{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"00_data_ETL_preprocessing.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pO6A3pqUR7Ob","executionInfo":{"status":"ok","timestamp":1622143068869,"user_tz":300,"elapsed":17367,"user":{"displayName":"Charlie Sheils","photoUrl":"","userId":"15125784101339103189"}},"outputId":"d7136ffe-4f4b-4b43-f6e3-41875e816945"},"source":["from google.colab import drive # Uncomment first time running notebook\n","drive.mount('/content/drive') # Uncomment first time running notebook\n","!ls \"/content/drive/Shareddrives/Advanced ML Project Spring 2021\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"," 01b_cnn_offline.ipynb\t\t\t   naive_bayes.ipynb\n","'2 - Upgraded Sentiment Analysis.ipynb'   'Nathan Lit Review.gdoc'\n"," charlie_midterm_presentation_backup.mp4   notebooks\n","'Data sources.gdoc'\t\t\t  'Project To-Do List.gdoc'\n","'Final presentation.gslides'\t\t  'Proposal ideas.gdoc'\n","'Final report.gdoc'\t\t\t  'Proposal (Rough Draft).gdoc'\n"," intermediate_data\t\t\t   raw_data\n"," LSTM.ipynb\t\t\t\t   RNN.ipynb\n","'Mid-quarter presentation.gslides'\t   scraped_data\n"," naive_bayes_final.ipynb\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7jQu8w2jSXlh"},"source":["**Functions to load data (descriptions in docstrings)**"]},{"cell_type":"code","metadata":{"id":"NMVtaIxyKb0E"},"source":["# follows https://github.com/walkerdb/supreme_court_transcripts\n","import os\n","import urllib.request, json\n","import numpy as np\n","import pandas as pd\n","import string\n","\n","SHARED_DRIVE_BASE_FOLDER = \"/content/drive/Shareddrives/Advanced ML Project Spring 2021/\"\n","LABEL_VAR = 'partyWinning' # 'caseDisposition'\n","TEXT_VAR = 'text'\n","\n","def get_oral_argument_text(term, docket_number):\n","    '''\n","    Given a term (year) and a docket_number, get the oral argument (text string)\n","    for a case from oyez.org.\n","    Inputs:\n","        term: string or int: 4-digit year\n","        docket_number: string or int: case docket number\n","    Returns:\n","        (str) full text of oral argument transcript\n","    '''\n","    # https://stackoverflow.com/questions/12965203/how-to-get-json-from-webpage-into-python-script\n","    base_url = f\"https://api.oyez.org/cases/{term}/{docket_number}\"\n","    with urllib.request.urlopen(base_url) as url:\n","        data = json.loads(url.read().decode())\n","    \n","    print(\"data['oral_argument_audio']:\", data['oral_argument_audio'])\n","    if not data['oral_argument_audio']:\n","        print(\"this case has no oral arguments\")\n","        print(term, docket_number)\n","        return None\n","    oral_argument_audio_url = data['oral_argument_audio'][0]['href']\n","\n","    # https://api.oyez.org/case_media/oral_argument_audio/14026\n","    with urllib.request.urlopen(oral_argument_audio_url) as url:\n","        transcript_json = json.loads(url.read().decode())\n","    transcript_text = \"\"\n","    if not transcript_json['transcript']:\n","        print(\"transcript_json.keys()\")\n","        print(transcript_json.keys())\n","        print(\"transcript_json['transcript']\")\n","        print(transcript_json['transcript'])\n","        print(\"this case has no transcript\")\n","        print(term, docket_number)\n","        return None\n","    for section in transcript_json['transcript']['sections']:\n","        section_blocks = [quote[\"text_blocks\"] for quote in section['turns']]\n","        for list_of_blocks in section_blocks:\n","            for block in list_of_blocks:\n","                transcript_text += \" \" + block[\"text\"]\n","    return transcript_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vqOfrn8XQWb3"},"source":["def get_scotus_oral_arguments(year):\n","    '''\n","    Web-scrapes all oral arguments for a given year from oyez.org.\n","    In addition to returning the list of dictionaries of cases, it is outputted\n","    to a JSON in the scraped_data folder.\n","    Inputs:\n","        year: int or string: 4-digit year\n","\n","    Returns:\n","        list of dictionaries of cases, of the form:\n","        [{\"year\": year,\n","        \"docket_number\": docket_number,\n","        \"text\": text},\n","        ...]\n","    '''\n","    scraped_data_folder = SHARED_DRIVE_BASE_FOLDER + \"scraped_data/\"\n","    if f\"scotus_oral_arguments_{year}.json\" in os.listdir(scraped_data_folder):\n","        print(\"year already scraped, loading from json from scraped_data folder\")\n","        with open(scraped_data_folder + f\"scotus_oral_arguments_{year}.json\") as fp:\n","            f = json.load(fp)\n","        return f\n","\n","    print(\"year not yet scraped, currently scraping (takes several minutes)\")\n","    year_url = f\"https://api.oyez.org/cases?per_page=0&filter=term:{year}\"\n","\n","    with urllib.request.urlopen(year_url) as url:\n","        year_data = json.loads(url.read().decode())\n","\n","    cases = []\n","    for case in year_data:\n","        docket_number = case['docket_number']\n","        text = get_oral_argument_text(year, docket_number)\n","        docket_dict = {\"year\": year,\n","                    \"docket_number\": docket_number,\n","                    \"text\": text}\n","        cases.append(docket_dict)\n","\n","    # Write data to JSON for future use\n","    with open(scraped_data_folder + f\"scotus_oral_arguments_{year}.json\", 'w') as f:\n","        json.dump(cases, f)\n","\n","    return cases"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Lan-f_kWYiU"},"source":["def merge_oral_argument_text_with_outcome_labels(oral_argument_list):\n","    '''\n","    Merge oral argument text with a case outcome variable, joining on docket\n","    number. Does an inner join, but displays the number of oral arguments that\n","    don't match to an outcome (see left_only) for logging purposes.\n","    Inputs:\n","        oral_argument_list: list of dictionaries of cases, of the form:\n","            [{\"year\": year,\n","            \"docket_number\": docket_number,\n","            \"text\": text},\n","            ...]\n","    Outputs:\n","        (Pandas df): merged dataframe of oral arguments and outcome variable\n","    '''\n","    decision_by_docket = pd.read_csv(SHARED_DRIVE_BASE_FOLDER + \"raw_data/SCDB_2020_01_caseCentered_Docket.csv\",\n","                                engine='python')\n","    decision_by_docket = decision_by_docket.astype({'partyWinning': float})\n","    oral_argument_df = pd.DataFrame(oral_argument_list)\n","\n","    # Drop cases with missing text\n","    oral_argument_df = oral_argument_df[~oral_argument_df[TEXT_VAR].isna()]\n","    # Drop duplicate cases, keeping the first (currently just 1 2007 case)\n","    oral_argument_df.drop_duplicates(subset=['docket_number'], inplace=True)\n","    merge_attempt = pd.merge(oral_argument_df, decision_by_docket,\n","                             how='left', indicator=True,\n","                             validate='1:m',\n","                             left_on='docket_number', right_on='docket')\n","    print(\"number of oral arguments that matched:\")\n","    print(merge_attempt['_merge'].value_counts(dropna=False))\n","    merge_attempt = pd.merge(oral_argument_df, decision_by_docket,\n","                             how='inner',\n","                             validate='1:m',\n","                             left_on='docket_number', right_on='docket')\n","    \n","    return merge_attempt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"17oJSMtJZuZ-"},"source":["def convert_merged_df_to_tuple_list(merged_df, label_var, text_var):\n","    '''\n","    Convert dataframe of oral arguments merged with outcome variable to a list\n","    of tuples, for use in NLP modeling.\n","\n","    Inputs:\n","        merged_df: (Pandas df) oral arguments merged with outcome variable\n","        label_var: (str) name of outcome/label variable in merged_df\n","        text_var: (str) name of text variable in merged_df (usually \"text\")\n","    Returns:\n","        list of tuples of form [(label, text),\n","                                ...]\n","    '''\n","\n","    # https://stackoverflow.com/questions/9758450/pandas-convert-dataframe-to-array-of-tuples\n","    tuple_list = list(merged_df[[label_var, text_var]].itertuples(index=False, name=None))\n","    return tuple_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r6ea0CH8lfyU"},"source":["def balance(data, target):\n","    '''\n","    Downsamples binary classification data to align majority class with \n","    minority class.\n","\n","    Inputs:\n","        data: Pandas dataframe with balanced outcomes\n","        target: (str) name of target/outcome variable\n","    Returns:\n","        Pandas dataframe with balanced outcomes\n","    '''\n","    # counts = data.partyWinning.value_counts().reset_index().rename(\n","    counts = data[target].value_counts().reset_index().rename(\n","        columns={'index': target, target: 'count'})\n","    \n","    count = max(counts['count'])\n","    print(\"count of majority party\")\n","    print(count)\n","    party = int(counts[counts['count'] == count][target])\n","    print(party)\n","    print(count)\n","    base = data[data[target] == party]\n","    minority_party = data[data[target] != party]\n","    sample = minority_party.iloc[np.random.randint(0, len(minority_party), size=count)]\n","    print(\"sample.head()\")\n","    print(sample.head())\n","    new_data = pd.concat([base, sample])\n","    print(new_data[target].value_counts())\n","    return new_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"33qZqnQZ5IjI"},"source":["def get_minority_party(data, target):\n","    '''\n","    Downsamples binary classification data to align majority class with \n","    minority class.\n","    Inputs:\n","        data: Pandas dataframe with balanced outcomes\n","        target: (str) name of target/outcome variable\n","    Returns:\n","        Pandas dataframe with balanced outcomes (downsampling)\n","    '''\n","\n","    counts = data[target].value_counts().reset_index().rename(\n","        columns={'index': target, target: 'count'})\n","    \n","    count = max(counts['count'])\n","    print(\"count of majority party\")\n","    print(count)\n","    party = int(counts[counts['count'] == count][target])\n","    print(party)\n","    print(count)\n","    base = data[data[target] == party]\n","    minority_party = data[data[target] != party]\n","    sample = minority_party.iloc[np.random.randint(0, len(minority_party), size=count)]\n","    print(\"sample.head()\")\n","    print(sample.head())\n","    new_data = pd.concat([base, sample])\n","    # print(new_data[target].value_counts())\n","    # return new_data\n","    return sample\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a_aLTyJCntny"},"source":["def preprocess_data(start_year, end_year, label_var, text_var, split=False,\n","                    balance_outcomes=False):\n","    '''\n","    Run all data extraction & preprocessing steps, saving output to a JSON\n","    file for future use.\n","    Inputs:\n","        start_year, end_year: ints of starting year and ending year of requested\n","            court data\n","        label_var: (str) name of column containing outcome/label variable\n","        text_var: (str) name of column containing text variable\n","        split: (bool) whether to train-test-validate split the data\n","        balance_outcomes: (bool) whether to balance the data on the label_var\n","    Returns:\n","        Pandas dataframe with columns label_var, text_var, 'docket',\n","            'docket_number', and 'year'\n","    '''\n","    oral_arguments_list = []\n","    for year in range(start_year, end_year+1):\n","        print(\"NOW GETTING YEAR\", year)\n","        oral_arguments_year = get_scotus_oral_arguments(year)\n","        print(\"year\", year, \"has length\", len(oral_arguments_year))\n","        oral_arguments_list += oral_arguments_year\n","\n","    print(\"len(oral_arguments_list)\")\n","    print(len(oral_arguments_list))\n","    merged_df = merge_oral_argument_text_with_outcome_labels(oral_arguments_list)\n","    print(\"merged_df.shape\")\n","    print(merged_df.shape)\n","    # Make sure that there are no duplicate docket_numbers (that cases aren't duplicated when merging)\n","    merged_df['dups'] = merged_df['docket_number'].duplicated()\n","    assert merged_df['dups'].all() == False\n","\n","    tuple_list = convert_merged_df_to_tuple_list(merged_df, LABEL_VAR, TEXT_VAR)\n","\n","    # Write tuple list to JSON for future use\n","    with open(SHARED_DRIVE_BASE_FOLDER + f\"intermediate_data/tuples_{start_year}-{end_year}.json\", 'w') as f:\n","        json.dump(tuple_list, f)\n","    intermediate_df = merged_df[[label_var, text_var, 'docket', 'docket_number', 'year']]\n","    final_df = merged_df[[label_var, text_var]]\n","    final_df[label_var] = final_df[label_var].astype(int)\n","\n","    # Strip punctuation (https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string)\n","    final_df[text_var] = final_df[text_var].apply(lambda x: x.lower().translate(\n","        str.maketrans('', '', string.punctuation)))\n","\n","    final_df = final_df[[label_var, text_var]]\n","    final_df = final_df.astype({'partyWinning': float})\n","    if split:\n","        # https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test\n","        train, validate, test = np.split(final_df.sample(frac=1, random_state=42),\n","                                     [int(.6*len(final_df)), int(.8*len(final_df))])\n","        if balance:\n","            train_balanced = balance(train, LABEL_VAR)\n","            train_balanced.to_csv(SHARED_DRIVE_BASE_FOLDER + f\"intermediate_data/train_balanced_{start_year}-{end_year}.csv\",\n","                                                            index=True)\n","            # minority_party_train = get_minority_party(train, LABEL_VAR)\n","            # minority_party_train.to_csv(SHARED_DRIVE_BASE_FOLDER + f\"intermediate_data/minority_party_train_{start_year}-{end_year}.csv\",\n","            #                                                 index=True)\n","            validate_balanced = balance(validate, LABEL_VAR)\n","            validate_balanced.to_csv(SHARED_DRIVE_BASE_FOLDER + f\"intermediate_data/validate_balanced_{start_year}-{end_year}.csv\",\n","                                                            index=True)\n","            # minority_party_validate = get_minority_party(validate, LABEL_VAR)\n","            # minority_party_validate.to_csv(SHARED_DRIVE_BASE_FOLDER + f\"intermediate_data/minority_party_validate_{start_year}-{end_year}.csv\",\n","            #                                                 index=True)\n","            test_balanced = balance(test, LABEL_VAR)\n","            test_balanced.to_csv(SHARED_DRIVE_BASE_FOLDER + f\"intermediate_data/test_balanced_{start_year}-{end_year}.csv\",\n","                                                            index=True)\n","            # minority_party = get_minority_party(test, LABEL_VAR)\n","            # minority_party.to_csv(SHARED_DRIVE_BASE_FOLDER + f\"intermediate_data/minority_party_test_{start_year}-{end_year}.csv\",\n","            #                                                 index=True)\n","\n","        else:\n","            train.to_csv(SHARED_DRIVE_BASE_FOLDER + f\"intermediate_data/train_{start_year}-{end_year}.csv\",\n","                                                            index=True)\n","            validate.to_csv(SHARED_DRIVE_BASE_FOLDER + f\"intermediate_data/validate_{start_year}-{end_year}.csv\",\n","                                                            index=True)\n","            test.to_csv(SHARED_DRIVE_BASE_FOLDER + f\"intermediate_data/test_{start_year}-{end_year}.csv\",\n","                                                            index=True)\n","    else:\n","        if balance:\n","            final_balanced = balance(final_df, LABEL_VAR)\n","            final_balanced.to_csv(SHARED_DRIVE_BASE_FOLDER + f\"intermediate_data/data_balanced_{start_year}-{end_year}.csv\",\n","                                                            index=True)\n","        else:\n","            final_df.to_csv(SHARED_DRIVE_BASE_FOLDER + f\"intermediate_data/data_{start_year}-{end_year}.csv\",\n","                                                            index=True)\n","    return intermediate_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rvvr47_PSNYu"},"source":["**Run pre-processing for years 2001-2019, outputting files to local folder**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"St02it5IsrUC","executionInfo":{"status":"ok","timestamp":1621817088537,"user_tz":300,"elapsed":5731,"user":{"displayName":"Charlie Sheils","photoUrl":"","userId":"15125784101339103189"}},"outputId":"47dec1a9-f569-4c26-bd7b-9c28f7fb2d59"},"source":["test_multiple_years = preprocess_data(2001, 2019, LABEL_VAR, TEXT_VAR,\n","                                      split=False, balance_outcomes=True)\n","test_multiple_years"],"execution_count":null,"outputs":[{"output_type":"stream","text":["NOW GETTING YEAR 2001\n","year already scraped, loading from json from scraped_data folder\n","year 2001 has length 84\n","NOW GETTING YEAR 2002\n","year already scraped, loading from json from scraped_data folder\n","year 2002 has length 85\n","NOW GETTING YEAR 2003\n","year already scraped, loading from json from scraped_data folder\n","year 2003 has length 81\n","NOW GETTING YEAR 2004\n","year already scraped, loading from json from scraped_data folder\n","year 2004 has length 80\n","NOW GETTING YEAR 2005\n","year already scraped, loading from json from scraped_data folder\n","year 2005 has length 89\n","NOW GETTING YEAR 2006\n","year already scraped, loading from json from scraped_data folder\n","year 2006 has length 77\n","NOW GETTING YEAR 2007\n","year already scraped, loading from json from scraped_data folder\n","year 2007 has length 75\n","NOW GETTING YEAR 2008\n","year already scraped, loading from json from scraped_data folder\n","year 2008 has length 83\n","NOW GETTING YEAR 2009\n","year already scraped, loading from json from scraped_data folder\n","year 2009 has length 87\n","NOW GETTING YEAR 2010\n","year already scraped, loading from json from scraped_data folder\n","year 2010 has length 82\n","NOW GETTING YEAR 2011\n","year already scraped, loading from json from scraped_data folder\n","year 2011 has length 80\n","NOW GETTING YEAR 2012\n","year already scraped, loading from json from scraped_data folder\n","year 2012 has length 80\n","NOW GETTING YEAR 2013\n","year already scraped, loading from json from scraped_data folder\n","year 2013 has length 78\n","NOW GETTING YEAR 2014\n","year already scraped, loading from json from scraped_data folder\n","year 2014 has length 76\n","NOW GETTING YEAR 2015\n","year already scraped, loading from json from scraped_data folder\n","year 2015 has length 81\n","NOW GETTING YEAR 2016\n","year already scraped, loading from json from scraped_data folder\n","year 2016 has length 72\n","NOW GETTING YEAR 2017\n","year already scraped, loading from json from scraped_data folder\n","year 2017 has length 79\n","NOW GETTING YEAR 2018\n","year already scraped, loading from json from scraped_data folder\n","year 2018 has length 76\n","NOW GETTING YEAR 2019\n","year already scraped, loading from json from scraped_data folder\n","year 2019 has length 61\n","len(oral_arguments_list)\n","1506\n","number of oral arguments that matched:\n","both          1322\n","left_only       12\n","right_only       0\n","Name: _merge, dtype: int64\n","merged_df.shape\n","(1322, 56)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"},{"output_type":"stream","text":["count of majority party\n","873\n","1\n","873\n","sample.head()\n","      partyWinning                                               text\n","1031           0.0   well hear argument first this morning in case...\n","1283           0.0   well hear argument first this morning in case...\n","165            0.0   well hear argument now in no 02891 the centra...\n","917            0.0   we will hear argument first this morning in c...\n","857            0.0   well hear argument first this morning in case...\n","1.0    873\n","0.0    871\n","2.0      2\n","Name: partyWinning, dtype: int64\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>partyWinning</th>\n","      <th>text</th>\n","      <th>docket</th>\n","      <th>docket_number</th>\n","      <th>year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>We'll hear argument first this morning in Num...</td>\n","      <td>00-507</td>\n","      <td>00-507</td>\n","      <td>2001</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>We'll hear argument next in Number 00-1853, A...</td>\n","      <td>00-1853</td>\n","      <td>00-1853</td>\n","      <td>2001</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>We'll hear argument now in Number oh oh ten e...</td>\n","      <td>00-1089</td>\n","      <td>00-1089</td>\n","      <td>2001</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>We'll hear argument next in Number oh oh twel...</td>\n","      <td>00-1250</td>\n","      <td>00-1250</td>\n","      <td>2001</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>Mr. Chief Justice, and may it please the Cour...</td>\n","      <td>00-927</td>\n","      <td>00-927</td>\n","      <td>2001</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1317</th>\n","      <td>1.0</td>\n","      <td>We'll hear argument next in Case Number 19-26...</td>\n","      <td>19-267</td>\n","      <td>19-267</td>\n","      <td>2019</td>\n","    </tr>\n","    <tr>\n","      <th>1318</th>\n","      <td>0.0</td>\n","      <td>We'll hear argument next in Case 19-631, Will...</td>\n","      <td>19-631</td>\n","      <td>19-631</td>\n","      <td>2019</td>\n","    </tr>\n","    <tr>\n","      <th>1319</th>\n","      <td>1.0</td>\n","      <td>We will hear argument first this morning in C...</td>\n","      <td>19-431</td>\n","      <td>19-431</td>\n","      <td>2019</td>\n","    </tr>\n","    <tr>\n","      <th>1320</th>\n","      <td>0.0</td>\n","      <td>We will hear argument first this morning in C...</td>\n","      <td>19-465</td>\n","      <td>19-465</td>\n","      <td>2019</td>\n","    </tr>\n","    <tr>\n","      <th>1321</th>\n","      <td>1.0</td>\n","      <td>We'll hear argument next in Case Number 19-51...</td>\n","      <td>19-518</td>\n","      <td>19-518</td>\n","      <td>2019</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1322 rows × 5 columns</p>\n","</div>"],"text/plain":["      partyWinning  ...  year\n","0              0.0  ...  2001\n","1              1.0  ...  2001\n","2              1.0  ...  2001\n","3              1.0  ...  2001\n","4              1.0  ...  2001\n","...            ...  ...   ...\n","1317           1.0  ...  2019\n","1318           0.0  ...  2019\n","1319           1.0  ...  2019\n","1320           0.0  ...  2019\n","1321           1.0  ...  2019\n","\n","[1322 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"Hew4k3IvRmbD"},"source":["**Look at cases labeled as outcome = 2**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"Y3c51Hx_vqA6","executionInfo":{"status":"ok","timestamp":1621817089117,"user_tz":300,"elapsed":13,"user":{"displayName":"Charlie Sheils","photoUrl":"","userId":"15125784101339103189"}},"outputId":"866e8fa2-15e1-44df-f80d-80b5777fdc0f"},"source":["test_multiple_years['dups'] = test_multiple_years.duplicated(subset=['docket'], keep=False)\n","test_multiple_years[test_multiple_years['dups']]\n","# test_multiple_years.columns\n","test_multiple_years[test_multiple_years['partyWinning'] == 2]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>partyWinning</th>\n","      <th>text</th>\n","      <th>docket</th>\n","      <th>docket_number</th>\n","      <th>year</th>\n","      <th>dups</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10</th>\n","      <td>2.0</td>\n","      <td>We'll hear argument first this morning in Num...</td>\n","      <td>00-878</td>\n","      <td>00-878</td>\n","      <td>2001</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1265</th>\n","      <td>2.0</td>\n","      <td>We'll hear argument first this morning in Cas...</td>\n","      <td>18-280</td>\n","      <td>18-280</td>\n","      <td>2019</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1279</th>\n","      <td>2.0</td>\n","      <td>We'll hear argument next in Case 18-1165, the...</td>\n","      <td>18-1165</td>\n","      <td>18-1165</td>\n","      <td>2019</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      partyWinning  ...   dups\n","10             2.0  ...  False\n","1265           2.0  ...  False\n","1279           2.0  ...  False\n","\n","[3 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"EGb9FEjUR8eF"},"source":["**Tables for visualizations**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_DJWV8aQaQ0","executionInfo":{"status":"ok","timestamp":1622143138777,"user_tz":300,"elapsed":27374,"user":{"displayName":"Charlie Sheils","photoUrl":"","userId":"15125784101339103189"}},"outputId":"5ab8ad35-7562-4538-bcf9-f9a7982e049a"},"source":["df_for_viz = preprocess_data(2001, 2019, LABEL_VAR, TEXT_VAR,\n","                                      split=False, balance_outcomes=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["NOW GETTING YEAR 2001\n","year already scraped, loading from json from scraped_data folder\n","year 2001 has length 84\n","NOW GETTING YEAR 2002\n","year already scraped, loading from json from scraped_data folder\n","year 2002 has length 85\n","NOW GETTING YEAR 2003\n","year already scraped, loading from json from scraped_data folder\n","year 2003 has length 81\n","NOW GETTING YEAR 2004\n","year already scraped, loading from json from scraped_data folder\n","year 2004 has length 80\n","NOW GETTING YEAR 2005\n","year already scraped, loading from json from scraped_data folder\n","year 2005 has length 89\n","NOW GETTING YEAR 2006\n","year already scraped, loading from json from scraped_data folder\n","year 2006 has length 77\n","NOW GETTING YEAR 2007\n","year already scraped, loading from json from scraped_data folder\n","year 2007 has length 75\n","NOW GETTING YEAR 2008\n","year already scraped, loading from json from scraped_data folder\n","year 2008 has length 83\n","NOW GETTING YEAR 2009\n","year already scraped, loading from json from scraped_data folder\n","year 2009 has length 87\n","NOW GETTING YEAR 2010\n","year already scraped, loading from json from scraped_data folder\n","year 2010 has length 82\n","NOW GETTING YEAR 2011\n","year already scraped, loading from json from scraped_data folder\n","year 2011 has length 80\n","NOW GETTING YEAR 2012\n","year already scraped, loading from json from scraped_data folder\n","year 2012 has length 80\n","NOW GETTING YEAR 2013\n","year already scraped, loading from json from scraped_data folder\n","year 2013 has length 78\n","NOW GETTING YEAR 2014\n","year already scraped, loading from json from scraped_data folder\n","year 2014 has length 76\n","NOW GETTING YEAR 2015\n","year already scraped, loading from json from scraped_data folder\n","year 2015 has length 81\n","NOW GETTING YEAR 2016\n","year already scraped, loading from json from scraped_data folder\n","year 2016 has length 72\n","NOW GETTING YEAR 2017\n","year already scraped, loading from json from scraped_data folder\n","year 2017 has length 79\n","NOW GETTING YEAR 2018\n","year already scraped, loading from json from scraped_data folder\n","year 2018 has length 76\n","NOW GETTING YEAR 2019\n","year already scraped, loading from json from scraped_data folder\n","year 2019 has length 61\n","len(oral_arguments_list)\n","1506\n","number of oral arguments that matched:\n","both          1322\n","left_only       12\n","right_only       0\n","Name: _merge, dtype: int64\n","merged_df.shape\n","(1322, 56)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"},{"output_type":"stream","text":["count of majority party\n","873\n","1\n","873\n","sample.head()\n","      partyWinning                                               text\n","336            0.0   well hear argument first this morning in mart...\n","436            0.0   well hear argument next in case 065306 bowles...\n","344            0.0   well hear argument next in clark versus arizo...\n","490            0.0   well hear argument first this morning in case...\n","1028           0.0   well hear argument first this morning in case...\n","1.0    873\n","0.0    866\n","2.0      7\n","Name: partyWinning, dtype: int64\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"pCxyPVaxQ_Nz","executionInfo":{"status":"ok","timestamp":1622143246334,"user_tz":300,"elapsed":154,"user":{"displayName":"Charlie Sheils","photoUrl":"","userId":"15125784101339103189"}},"outputId":"4ef1f8c6-e04e-4eb3-b9b0-e894737eaf0a"},"source":["# Count of cases by year and outcome variable\n","df_for_viz.groupby(['year', 'partyWinning']).count()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>text</th>\n","      <th>docket</th>\n","      <th>docket_number</th>\n","    </tr>\n","    <tr>\n","      <th>year</th>\n","      <th>partyWinning</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">2001</th>\n","      <th>0.0</th>\n","      <td>24</td>\n","      <td>24</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>52</td>\n","      <td>52</td>\n","      <td>52</td>\n","    </tr>\n","    <tr>\n","      <th>2.0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2002</th>\n","      <th>0.0</th>\n","      <td>26</td>\n","      <td>26</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>50</td>\n","      <td>50</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2003</th>\n","      <th>0.0</th>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>54</td>\n","      <td>54</td>\n","      <td>54</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2004</th>\n","      <th>0.0</th>\n","      <td>23</td>\n","      <td>23</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>50</td>\n","      <td>50</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2005</th>\n","      <th>0.0</th>\n","      <td>25</td>\n","      <td>25</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>50</td>\n","      <td>50</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2006</th>\n","      <th>0.0</th>\n","      <td>23</td>\n","      <td>23</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>48</td>\n","      <td>48</td>\n","      <td>48</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2007</th>\n","      <th>0.0</th>\n","      <td>28</td>\n","      <td>28</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>42</td>\n","      <td>42</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2008</th>\n","      <th>0.0</th>\n","      <td>19</td>\n","      <td>19</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>58</td>\n","      <td>58</td>\n","      <td>58</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2009</th>\n","      <th>0.0</th>\n","      <td>21</td>\n","      <td>21</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>54</td>\n","      <td>54</td>\n","      <td>54</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2010</th>\n","      <th>0.0</th>\n","      <td>25</td>\n","      <td>25</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>52</td>\n","      <td>52</td>\n","      <td>52</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2011</th>\n","      <th>0.0</th>\n","      <td>34</td>\n","      <td>34</td>\n","      <td>34</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>35</td>\n","      <td>35</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2012</th>\n","      <th>0.0</th>\n","      <td>24</td>\n","      <td>24</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>49</td>\n","      <td>49</td>\n","      <td>49</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2013</th>\n","      <th>0.0</th>\n","      <td>21</td>\n","      <td>21</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>45</td>\n","      <td>45</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2014</th>\n","      <th>0.0</th>\n","      <td>17</td>\n","      <td>17</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>36</td>\n","      <td>36</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2015</th>\n","      <th>0.0</th>\n","      <td>32</td>\n","      <td>32</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>36</td>\n","      <td>36</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2016</th>\n","      <th>0.0</th>\n","      <td>15</td>\n","      <td>15</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>46</td>\n","      <td>46</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2017</th>\n","      <th>0.0</th>\n","      <td>19</td>\n","      <td>19</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>42</td>\n","      <td>42</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2018</th>\n","      <th>0.0</th>\n","      <td>29</td>\n","      <td>29</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>40</td>\n","      <td>40</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">2019</th>\n","      <th>0.0</th>\n","      <td>21</td>\n","      <td>21</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>34</td>\n","      <td>34</td>\n","      <td>34</td>\n","    </tr>\n","    <tr>\n","      <th>2.0</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   text  docket  docket_number\n","year partyWinning                             \n","2001 0.0             24      24             24\n","     1.0             52      52             52\n","     2.0              1       1              1\n","2002 0.0             26      26             26\n","     1.0             50      50             50\n","2003 0.0             20      20             20\n","     1.0             54      54             54\n","2004 0.0             23      23             23\n","     1.0             50      50             50\n","2005 0.0             25      25             25\n","     1.0             50      50             50\n","2006 0.0             23      23             23\n","     1.0             48      48             48\n","2007 0.0             28      28             28\n","     1.0             42      42             42\n","2008 0.0             19      19             19\n","     1.0             58      58             58\n","2009 0.0             21      21             21\n","     1.0             54      54             54\n","2010 0.0             25      25             25\n","     1.0             52      52             52\n","2011 0.0             34      34             34\n","     1.0             35      35             35\n","2012 0.0             24      24             24\n","     1.0             49      49             49\n","2013 0.0             21      21             21\n","     1.0             45      45             45\n","2014 0.0             17      17             17\n","     1.0             36      36             36\n","2015 0.0             32      32             32\n","     1.0             36      36             36\n","2016 0.0             15      15             15\n","     1.0             46      46             46\n","2017 0.0             19      19             19\n","     1.0             42      42             42\n","2018 0.0             29      29             29\n","     1.0             40      40             40\n","2019 0.0             21      21             21\n","     1.0             34      34             34\n","     2.0              2       2              2"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":669},"id":"HVyrqrOIRgJ5","executionInfo":{"status":"ok","timestamp":1622143354039,"user_tz":300,"elapsed":149,"user":{"displayName":"Charlie Sheils","photoUrl":"","userId":"15125784101339103189"}},"outputId":"4163e949-167d-4cdb-94a9-a83a3767a578"},"source":["# Count of cases by year\n","counts_df= df_for_viz[['docket', 'year']].groupby(['year']).count()\n","counts_df.columns = ['Docket Count']\n","counts_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Docket Count</th>\n","    </tr>\n","    <tr>\n","      <th>year</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2001</th>\n","      <td>77</td>\n","    </tr>\n","    <tr>\n","      <th>2002</th>\n","      <td>76</td>\n","    </tr>\n","    <tr>\n","      <th>2003</th>\n","      <td>74</td>\n","    </tr>\n","    <tr>\n","      <th>2004</th>\n","      <td>73</td>\n","    </tr>\n","    <tr>\n","      <th>2005</th>\n","      <td>75</td>\n","    </tr>\n","    <tr>\n","      <th>2006</th>\n","      <td>71</td>\n","    </tr>\n","    <tr>\n","      <th>2007</th>\n","      <td>70</td>\n","    </tr>\n","    <tr>\n","      <th>2008</th>\n","      <td>77</td>\n","    </tr>\n","    <tr>\n","      <th>2009</th>\n","      <td>75</td>\n","    </tr>\n","    <tr>\n","      <th>2010</th>\n","      <td>77</td>\n","    </tr>\n","    <tr>\n","      <th>2011</th>\n","      <td>69</td>\n","    </tr>\n","    <tr>\n","      <th>2012</th>\n","      <td>73</td>\n","    </tr>\n","    <tr>\n","      <th>2013</th>\n","      <td>66</td>\n","    </tr>\n","    <tr>\n","      <th>2014</th>\n","      <td>53</td>\n","    </tr>\n","    <tr>\n","      <th>2015</th>\n","      <td>68</td>\n","    </tr>\n","    <tr>\n","      <th>2016</th>\n","      <td>61</td>\n","    </tr>\n","    <tr>\n","      <th>2017</th>\n","      <td>61</td>\n","    </tr>\n","    <tr>\n","      <th>2018</th>\n","      <td>69</td>\n","    </tr>\n","    <tr>\n","      <th>2019</th>\n","      <td>57</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Docket Count\n","year              \n","2001            77\n","2002            76\n","2003            74\n","2004            73\n","2005            75\n","2006            71\n","2007            70\n","2008            77\n","2009            75\n","2010            77\n","2011            69\n","2012            73\n","2013            66\n","2014            53\n","2015            68\n","2016            61\n","2017            61\n","2018            69\n","2019            57"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"l1w1EH6tRgoW","executionInfo":{"status":"ok","timestamp":1622143440668,"user_tz":300,"elapsed":148,"user":{"displayName":"Charlie Sheils","photoUrl":"","userId":"15125784101339103189"}},"outputId":"942efeae-18d8-4b89-b8b2-fd76ed0eb379"},"source":["# Count of cases by outcome variable\n","outcome_count_df = df_for_viz[['docket', 'partyWinning']].groupby(['partyWinning']).count()\n","outcome_count_df.columns=['Docket Count']\n","outcome_count_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Docket Count</th>\n","    </tr>\n","    <tr>\n","      <th>partyWinning</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0.0</th>\n","      <td>446</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>873</td>\n","    </tr>\n","    <tr>\n","      <th>2.0</th>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Docket Count\n","partyWinning              \n","0.0                    446\n","1.0                    873\n","2.0                      3"]},"metadata":{"tags":[]},"execution_count":22}]}]}